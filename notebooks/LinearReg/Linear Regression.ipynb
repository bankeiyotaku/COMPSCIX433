{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A module can be installed from within the notebook by \n",
    "# typing the following command\n",
    "\n",
    "\n",
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('Car_Purchasing_Data.csv')\n",
    "print(auto.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auto.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auto.columns)\n",
    "print(auto.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's our goal\n",
    "\n",
    "We have 9 columns. The dependent column is Car Purchase Amount. \n",
    "\n",
    "Since Customer Name, Customer e-mail and Country columns are catergorical variables and will not have any bearing on our prediction we will drop these columns now. \n",
    "\n",
    "Goal: We want to find a linear equation so that we can predict Car Purchase Amount. \n",
    "\n",
    "We will consider: Gender, Age, Annual Salary, Credit Card Debt and Net Worth as independent variables and Car Purchase Amount will be our dependent varaible also known as target variable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping \n",
    "\n",
    "auto.drop([\"Customer Name\", \"Customer e-mail\", \"Country\"], axis=1, inplace=True)\n",
    "\n",
    "#df.drop(['column_name1', 'column_name2'], axis=1, inplace=True)\n",
    "\n",
    "print(auto.shape)\n",
    "\n",
    "print(auto.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is correlation? \n",
    "\n",
    "Correlation describes the linear relationship between two variables. \n",
    "\n",
    "Correlation coefficient is a value that describes the strenght of the \n",
    "relationship between two variables. \n",
    "\n",
    "Correlation graph\n",
    "\n",
    "<img src=\"correlation_graph.png\" width=400, height=300>\n",
    "\n",
    "Correlation coefficient formula\n",
    "\n",
    "<img src=\"correlation_formula.png\" width=400, height=300>\n",
    "\n",
    "Values of $r$ range from -1 to 1, -1 represents negative correlation, 1 represents positive correlation. \n",
    "\n",
    "Reference - https://www.wallstreetmojo.com/correlation-coefficient-formula/\n",
    "\n",
    "Which features to select?\n",
    "\n",
    "Choose features that are not correlated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Basic correlogram\n",
    "sns.pairplot(auto)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.triu(auto.corr())\n",
    "\n",
    "ax = sns.heatmap(auto.corr(), annot = True, square=True, \\\n",
    "            linewidths=1, linecolor='black') #, mask=matrix)\n",
    "\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix = np.triu(auto.corr())\n",
    "\n",
    "ax = sns.heatmap(auto.corr(), annot = True, square=True, \\\n",
    "            linewidths=1, linecolor='black', mask=matrix)\n",
    "\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's list which variables are correlated with which:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilinear Regression\n",
    "\n",
    "In a multilinear regression, instead of one independent variable, we will consider more than one independent variable to find a linear relationship between independent variables and dependent variable. We will consider 5 independent variables to find a linear relationship between them and our target variable, Car Purchase Amount. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instance of LinearRegression class\n",
    "reg = linear_model.LinearRegression()\n",
    "print(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "x = all independent variables that we are considering for our study\n",
    "\n",
    "y = car purchase amount\n",
    "\n",
    "Goal: get a linear relationship between y and x.\n",
    "\n",
    "How many rows are there? \n",
    "\n",
    "The data is split so that we can use majority for training the model. Once the model is trained, we use the remaining data that was not used to test the model. \n",
    "\n",
    "y = y_known\n",
    "\n",
    "using the model we can y_predict.\n",
    "\n",
    "\n",
    "train_test_split() will return 4 things: x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "x_1  y_1\n",
    "\n",
    "x_2  y_2\n",
    "\n",
    "x_3  y_3\n",
    "\n",
    "x_4  y_4\n",
    "\n",
    "x_5  y_5\n",
    "\n",
    "\n",
    "x_train = [x_1, x_2,x_3,x_4]\n",
    "y_train = [y_1,y_2,y_3,y_4]\n",
    "\n",
    "x_test = [x_5]\n",
    "y_test = [y_5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Car Purchase min Amount: \", min(auto[\"Car Purchase Amount\"]))\n",
    "\n",
    "print(\"Car purchase max Amount: \", max(auto[\"Car Purchase Amount\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scaler\n",
    "\n",
    "We have to plot each feature and see if the distribution is normal. If yes, they we can perfrom standard scaler so that \n",
    "the mean will be zero and standard deviation will be 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_scaler = StandardScaler() # creating an instance of Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_independent = a_scaler.fit_transform(auto[['Age','Annual Salary', 'Credit Card Debt', 'Net Worth']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using train_test_split(), we are splitting the data into training and test \n",
    "# x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(auto_independent, auto[\"Car Purchase Amount\"], test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to fit the data\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = mx + b here m is the coefficient (or slope) of x \n",
    "# and b is the intercept\n",
    "\n",
    "print(reg.coef_) # \n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the relationship between the independent and dependent variables is \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for Linear Regression\n",
    "\n",
    "Mean Squared Error \n",
    "\n",
    "For linear regresion with one variable, $ y = mx +b  = wx + b$\n",
    "\n",
    "$ MSE = \\frac{1}{N} \\sum_{i=1}^{n} (y_i - (mx_i + b))^2 $ \n",
    "\n",
    "$y_i$ is the actual value and $mx_i + b$ is the predicted value.\n",
    "\n",
    "$N$ is the number of observations.\n",
    "\n",
    "The loss function based on the MSE is \n",
    "\n",
    "$ L(m, b) = \\frac{1}{N} \\sum_{i=1}^{n} (y_i - (mx_i + b))^2 $ \n",
    "\n",
    "our goal is to minimize $L$ with respect to $m$ and $b$\n",
    "\n",
    "The gradient of $L$\n",
    "\n",
    "$L'(m, b) = \\begin{bmatrix} \\frac{dL}{dm} \\\\ \\frac{dL}{db} \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{N} \\sum -x_i.2(y_i - (mx_i + b))  \\\\ \\frac{1}{N} \\sum -2(y_i - (mx_i + b))  \\end{bmatrix}$ \n",
    "\n",
    "Update equation of m and b with learning rate $\\epsilon$ is\n",
    "\n",
    "$ m_{new} = m_{old} - \\epsilon \\frac{dL}{dm} (m_{old}) $\n",
    "\n",
    "$ b_{new} = b_{old} - \\epsilon \\frac{dL}{db} (b_{old})$\n",
    "\n",
    "<img src=\"linear_loss.png\" width=400, height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "true  predicted true-predicted  (true-predicted)^2\n",
    "\n",
    "3       5        -2                 4\n",
    "\n",
    "5       3         2                 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Gradient Descents\n",
    "\n",
    "Gradient Descent - every single data point is considered for update. \n",
    "\n",
    "Batch Gradient Descent - A whole batch of data is considered and then an update is done. \n",
    "It is slow when the training data is large. \n",
    "\n",
    "Stochastic Gradient Descent - a single point at random is chosen and loss is computed for update. \n",
    "\n",
    "Mini-batch Stochastic Gradient Descent - a mini-batch of randomly selected data points is considered and the average loss of the mini-batch is computed for the update. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat stands for perdicted value of y and for this we \n",
    "# have to use the x_test values\n",
    "\n",
    "yhat = reg.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_test = mean_squared_error(y_test, yhat)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_t_predict is the predicted y values for the x_train data\n",
    "y_t_predict = reg.predict(x_train)\n",
    "\n",
    "# note that y_train is the true y value\n",
    "mse_train = mean_squared_error(y_train, y_t_predict)\n",
    "print(mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since MSE has no upper bound, we compute the ratio between \n",
    "# mse_test and mse_train or difference to see if \n",
    "# ratio is close to one and difference is less than 5%\n",
    "\n",
    "r1 = mse_test/mse_train\n",
    "\n",
    "diff1 = np.abs(mse_train - mse_test)\n",
    "\n",
    "print(r1)\n",
    "\n",
    "print(diff1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"r-squared for the test data: \", r2_score(y_test, yhat))\n",
    "    \n",
    "print(\"r-squared for the train data: \", r2_score(y_train, y_t_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "\n",
    "r-squared for test is  and for train is \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In-class activity: In the auto example, find the multi-linear relationship \n",
    "between 'Age','Annual Salary', 'Credit Card Debt' with 'Car Purchase Amount'. \n",
    "Find the mean squared error  and r-squared for test set \n",
    "and train set and make a conclusion. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear model example\n",
    "\n",
    "Building a linear model with one independent variable and one dependent variable.\n",
    "\n",
    "For this, we will consider the study time versus score from the pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of study time versus score from the pptx\n",
    "\n",
    "x = np.array([16, 34, 8, 38, 39, 40, 54, 21, 16, 67, 40, 43, 47, 56, 60, 80])\n",
    "y = np.array([50, 61, 45, 60, 60, 67, 65, 59, 57, 73, 68, 71, 75, 71, 88, 94])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape) \n",
    "y = y.reshape(-1,1) # -1 is used to access last values in a list or a tuple\n",
    "print(y.shape)\n",
    "x = x.reshape(-1,1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using train_test_split(), we are splitting the data into training and test \n",
    "# x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constraints are : minimum study time can be zero. \n",
    "# The max score can be 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ùë¶ = 43.562 + 0.577‚àó 75 \n",
    "print(43.562 + (0.577*75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max = 100\n",
    "x_input = 100\n",
    "y = 43.562 + 0.577*x_input\n",
    "print(y)\n",
    "lower = min(y, y_max)\n",
    "\n",
    "print(lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression calculator\n",
    "\n",
    "# https://www.socscistatistics.com/tests/regression/default.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources -\n",
    "https://towardsdatascience.com/differential-equations-basics-c72db0a8c42a\n",
    "\n",
    "Understandable Statistics: Concepts and Methods, Enhanced 11th Edition\n",
    "by Charles Henry Brase (Author), Corrinne Pellillo Brase (Author)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
